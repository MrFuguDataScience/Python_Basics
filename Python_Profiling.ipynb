{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=12 color=red>Scaling Data with Limited Memory</font> (Part 1 of 3) \n",
    "# <font color=blue>Python Profiling:</font> *(using the right tool for the situation)*\n",
    "\n",
    "# `Mr Fugu Data Science`\n",
    "\n",
    "# (◕‿◕✿)\n",
    "\n",
    "*Motivation*: `wouldn't it be better to see what the bottle neck is instead of getting an estimate or theoretical idea?`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ If you have a program with a function that takes say 10 minutes to run, is this 30% or 90% of the total run time?\n",
    "    + It would serve us to check if our code is also inefficient. But, without experience or guidance how would you know in the first place you have terribly slow or poorly written code?\n",
    "    \n",
    "*`Stepping back and doing a few things will aid in our inspection.`*\n",
    "+ Investigate the run time of our program\n",
    "    + Find functions that may be holding us back\n",
    "        + If needed from that more ganular approach do a line by line search when you start to narrow down areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Profiling:`** \n",
    "\n",
    "+ `Consider needing to find the time certain operations run in a script, NOT benching marking`. This is because you are running statistics on the entire program.\n",
    "    + In that case you would want to use something such as \"timeit\"\n",
    "\n",
    "`Two types of Profiling:`\n",
    "\n",
    "+ **Deterministic:**\n",
    "    * monitoring events, **`while being accurate will have an effect on performance overhead`**. This would be better run on small functions or operations.\n",
    "\n",
    "+ **Statistical:**\n",
    "    * **`Less accurate but also uses fewer overhead`** resources by taking samples.\n",
    "    \n",
    "Something really useful and pretty cools is the (Call Graph) look into **gprof2dot** for example. It will convert your script into a graph like structure showing what functions are calling each other.\n",
    "\n",
    "\n",
    "# `Other Tools:`\n",
    "\n",
    "    + vprof\n",
    "    + pyflame\n",
    "    + stackImpact\n",
    "    \n",
    "https://medium.com/@antoniomdk1/hpc-with-python-part-1-profiling-1dda4d172cdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Native Python Profiling examples :` \n",
    "\n",
    "+ **`Timeit:`** benchmark code blocks or lines of code\n",
    "    + Not used on entire program\n",
    "    + Code needs to be isolated\n",
    "    \n",
    "+ **`Cprofile:`** runs on entire program\n",
    "    + evaluates each funcation call, then gives average time for those calls and a list of most frequent\n",
    "        + Downside: high overhead, do not use this for production work! Consider, only for development.\n",
    "\n",
    "+ **`Time:`** just a stop watch \n",
    "    + not able to run an entire program \n",
    "    \n",
    "    \n",
    "\n",
    "[external resources](https://www.infoworld.com/article/3600993/9-nifty-libraries-for-profiling-python-code.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Always, consider what your 'profiler' is measuring to get an idea of if it is best for your circumstance!`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Time:` measuring the time for our code in a single run\n",
    "\n",
    "# `Ex.)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `TimeIT:` execution time over multiple passes \"runs\"\n",
    "\n",
    "# `Ex.)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Cprofile:`\n",
    "+ Measures wall clock time,think of this as elapsed time\n",
    "    + Consider it as if we are measuring the time for a function to run\n",
    "        + `You are NOT looking at every line of code!`\n",
    "            + In that case you would need to do something else like a `line profiler`\n",
    "+ Deterministic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `EX.)`\n",
    "\n",
    "Your basic old script you call in the interpretor:\n",
    "\n",
    "`$ python3 some_file.py`\n",
    "\n",
    "If you would like to use Cprofile\n",
    "\n",
    "`$ python3 -m cprofile some_file.py`\n",
    "\n",
    "[command line flags & similar](https://www.ibm.com/docs/en/aix/7.1?topic=names-command-parameters) | [beginner command line flags](https://jgefroh.medium.com/a-beginners-guide-to-linux-command-line-56a8004e2471)\n",
    "\n",
    "* `There is an issue that you need to consider: the printout of this will generate a table containing the functions called but have no idea of relationship to each other such as dependency`\n",
    "\n",
    "**`Problems 'Cons': \n",
    "1.) Large overhead\n",
    "2.) Printout of each function represented by a line\n",
    "3.) Real world use will be an issue and you should expect slower results\n",
    "4.) Very important note: you may have slow code for a specific function and you can also have a function slow for specific inputs!`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Profiling Static & Dynamic data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line Profiler: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `External Software to visually see usuage`\n",
    "\n",
    "`Ex.)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Optimizing:`\n",
    "\n",
    "+ Be careful when optimizing code due to the fact that you can start introducing difficult code to manage, update or read.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real World Usuage (Example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good Reading resource:\n",
    "\n",
    "https://nyu-cds.github.io/python-performance-tuning/02-cprofile/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Please Like, Share &` <font color=red>SUB</font>`scribe`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Citations & Help:`\n",
    "\n",
    "# ◔̯◔\n",
    "\n",
    "\n",
    "https://www.toucantoco.com/en/tech-blog/python-performance-optimization\n",
    "\n",
    "https://wiki.python.org/moin/PythonSpeed/PerformanceTips#Profiling_Code\n",
    "\n",
    "https://stackoverflow.com/questions/582336/how-do-i-profile-a-python-script\n",
    "\n",
    "https://machinelearningmastery.com/profiling-python-code/ \n",
    "\n",
    "https://www.infoworld.com/article/3600993/9-nifty-libraries-for-profiling-python-code.html\n",
    "\n",
    "https://medium.com/@narenandu/profiling-and-visualization-tools-in-python-89a46f578989\n",
    "\n",
    "https://towardsdatascience.com/how-to-profile-your-code-in-python-e70c834fad89\n",
    "\n",
    "https://pythonspeed.com/articles/beyond-cprofile/\n",
    "\n",
    "https://betterprogramming.pub/a-comprehensive-guide-to-profiling-python-programs-f8b7db772e6\n",
    "\n",
    "https://medium.com/geekculture/profiling-and-optimizing-your-python-code-64fe694b7f7f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
