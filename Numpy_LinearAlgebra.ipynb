{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Linear Algebra using Numpy`\n",
    "\n",
    "# <font color=red>Mr Fugu Data Science</font>\n",
    "\n",
    "# (◕‿◕✿)\n",
    "\n",
    "# `Purpose & Outcome:`\n",
    "\n",
    "+ Learn new numpy operations\n",
    "+ Practice linear algebra\n",
    "    + brush up on how operations work by example\n",
    "\n",
    "**Help Support the Channel: Buy Me A Coffee @mrfugudatasci**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.18.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__ # if you were wondering what version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Eigen values and vectors:`\n",
    "\n",
    "<font size=4>**$Ax=\\lambda x$**</font>, where **$\\lambda$** is our eigen value of A\n",
    "+ It deals with shrinking and stretching of vector ( x )\n",
    "    + If the eigenvalue is zero, then we have a nullspace\n",
    "+ the determinant <font size=4>$(A-\\lambda I)=0$</font>\n",
    "\n",
    "\n",
    "`------------------------------`\n",
    "+ If you have a square matrix consider using: `np.linalg.eigh( )` for speed\n",
    "\n",
    "# Ex.)  $$A=\\begin{bmatrix} 1 & 0 \\\\ -3 & 2  \\end{bmatrix}$$\n",
    "\n",
    "Let us solve this:\n",
    "\n",
    "$det\\begin{bmatrix} 1-\\lambda & 0 \\\\ -3& 2-\\lambda   \\end{bmatrix}$\n",
    "\n",
    "$=(1-\\lambda)(2-\\lambda)-(3)*(0)$\n",
    "\n",
    "`factor this and use completing the squares`\n",
    "\n",
    "$=\\lambda^2-3\\lambda+2$\n",
    "\n",
    "$=(\\lambda-1)(\\lambda-2)$\n",
    "\n",
    "$\\lambda=1,2$ `finally our eigen values yippie.`\n",
    "\n",
    "`---------------------------`\n",
    "\n",
    "`Eigen Vectors`\n",
    "\n",
    "Can solve with `Gaussian Elimination:`\n",
    "\n",
    "[theory eigenvalue/vectors M.I.T help](http://math.mit.edu/~gs/linearalgebra/ila0601.pdf) | [matrix calculator with steps shown](https://matrixcalc.org/en/vectors.html#eigenvectors%28%7B%7B1,0%7D,%7B-3,2%7D%7D%29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "a = np.array([[1,0], [-3,2]])\n",
    "eigenvalues, eigenvectors = np.linalg.eig(a)\n",
    "# Note: use eigh if your matrix is symmetric (faster)\n",
    "eigenvalues,eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 1.]),\n",
       " array([[0.        , 0.31622777],\n",
       "        [1.        , 0.9486833 ]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,0], [-3,2]])\n",
    "eigenvalues, eigenvectors = np.linalg.eig(a)\n",
    "\n",
    "eigenvalues,eigenvectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Hermitian Matrix:`\n",
    "\n",
    "<font size=4>$A^{\\theta}=A^T$</font>, the conjugate of (A) equals (A) transpose\n",
    "\n",
    "$A=\\begin{bmatrix} 6&2-j&4 \\\\ 2+j&-3&-j\\\\4&j&9   \\end{bmatrix}$\n",
    "\n",
    "`then`\n",
    "$A^{\\theta}=\\begin{bmatrix} 6&2+j&4 \\\\ 2-j&-3&j\\\\4&-j&9   \\end{bmatrix}$ = $A^T=\\begin{bmatrix} 6&2+j&4 \\\\ 2-j&-3&j\\\\ 4&-j&9  \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(a)\n",
    "eigenvalues, eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.54138127,  4.54138127]),\n",
       " array([[-0.76301998, -0.6463749 ],\n",
       "        [-0.6463749 ,  0.76301998]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,0], [-3,2]])\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(a)\n",
    "eigenvalues, eigenvectors\n",
    "np.linalg.eigh(a_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Trace:`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# offset trace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose and Inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# systems of equations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `Banded Matrices:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Using Least Squares: np.linalg.lstsq(A,b)`\n",
    "+ Under the hood uses SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Solving Linear Systems with: np.linalg.solve()`\n",
    "+ (A) must be a square and full-rank matrix: All of its \n",
    "rows must be be linearly independent. \n",
    "+ (A) should be invertible/non-singular (its determinant is not zero)\n",
    "\n",
    "# Ex.) two equations and two unknowns\n",
    "\n",
    "$x_1+x_2=30$\n",
    "\n",
    "$6x_1+2.3x_2=44$\n",
    "\n",
    "\n",
    "we will use `Ax=b` to solve this problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ax=b -> [A^-1]*b, but dont directly instead with .solve()\n",
    "A = np.array([[1,1],[6,2.3]])\n",
    "b= np.array([30,44])\n",
    "\n",
    "np.linalg.solve(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "np.linalg.solve(A,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `we could use: np.linalg.inv(A).dot(B)`\n",
    "\n",
    "To solve the problem from above, but there is a caveat and considerations.\n",
    "+ When using numpy we have two options to solve this problem, one is faster than the other.\n",
    "Let's take into account our other option and how it can inhibit our computations/time.\n",
    "\n",
    "+ We are starting with `Ax=b ->`$x=A^{-1}*b$ but computing the inverse is time consuming for a few reasons as well as resources allocated.\n",
    "\n",
    "`Direct version`\n",
    "Let's understand how `np.linalg.solve()` works.\n",
    "+ we are not calculating the inverse, instead we are using LAPACK routine.\n",
    "    + Then LU decomposition is used to find the values using forward/back substitution.\n",
    " \n",
    "`Slower version & (can be) Not as accurate`\n",
    "Now, `np.linalg.inv(A).dot(B)`\n",
    "+ you are using more floating point operations to solve the inverse\n",
    "    + If (A) is an ill-conditioned matrix you will have inaccuracy\n",
    "    + useless steps that are unneeded while computing\n",
    " \n",
    "[.solve() vs .inv.dot()](https://stackoverflow.com/questions/31256252/why-does-numpy-linalg-solve-offer-more-precise-matrix-inversions-than-numpy-li) | [LAPACK background](http://www.netlib.org/lapack/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.inv(A).dot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "np.linalg.inv(A).dot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `Least Squares:` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dot Product, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Matrix Multiplication:`\n",
    "\n",
    "<font size=4>$A=\\begin{bmatrix} 1&2&3&4 \\\\ 5&6&7&8\\\\9&10&11&12   \\end{bmatrix}_{ 3x4}$\n",
    ",$B=\\begin{bmatrix} 2&4&6 \\\\ 8&10&12\\\\14&16&18  \\end{bmatrix}_{ 3x3}$</font>\n",
    "\n",
    "we have a $(3x4)(3x3)=(?)$, depends transpose and order of matrices `3x4 or 4x3`\n",
    "\n",
    "<font size=4>$[A^TB]_{3x4}$ versus $[BA^T]_{3x4}$</font>\n",
    "\n",
    "`Order MATTERS~`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Rank:`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Multiple Linear Regression:`\n",
    "\n",
    "<font size=4>$$</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red>Like</font>,Share &\n",
    "\n",
    "# <font color=red>SUB</font>scribe\n",
    "\n",
    "**`Help Support the channel: Buy Me A Coffee @mrfugudatasci`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Citations & Help:`\n",
    "\n",
    "# ◔̯◔\n",
    "\n",
    "https://www.bogotobogo.com/python/python_numpy_matrix_tutorial.php\n",
    "\n",
    "https://www.twilio.com/blog/2018/06/data-science-linear-algebra-python-scipy-numpy.html\n",
    "\n",
    "http://www2.lawrence.edu/fast/GREGGJ/Python/numpy/numpyLA.html\n",
    "\n",
    "https://web.stanford.edu/class/cs231a/section/section1.pdf\n",
    "\n",
    "http://snowball.millersville.edu/~adecaria/ESCI386P/esci386-lesson18-Linear-Algebra.pdf\n",
    "\n",
    "https://courses.cs.washington.edu/courses/cse446/20wi/Section1/linear_algebra.html\n",
    "\n",
    "https://sites.calvin.edu/scofield/courses/m256/materials/eigenstuff.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
